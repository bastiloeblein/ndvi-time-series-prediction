{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d1b5e6d-e97f-4750-ae5b-292a9457dcab",
   "metadata": {},
   "source": [
    "# Random Forest Model\n",
    "\n",
    "Random Forest is an ensemble method that is based on decision-tree procedures. The method builds single decision trees using bootstrapping to repeatedly select random samples from the training data with replacement. This means that some samples may be repeated in the bootstrap sample while others are left out. From each of these samples a random subset of variables is selected. The samples that are not included in the bootstrap sample for a particular tree are known as out-of-bag (OOB) samples. On average, about one-third of the training data is left out as OOB samples for each tree. The predictions of the trees are averaged across all decision trees. This results in an improved prediction accuracy and prevents overfitting [@breiman2001random]. \n",
    "Depending on size of training set, a few hundred to several thousand trees are necessary. Here, only 100 trees are used due to processing time and memory problems.\n",
    "\n",
    "## Overview\n",
    "1. import packages\n",
    "2. define base directory\n",
    "3. define functions\n",
    "4. load data and define variables\n",
    "5. train model and make prediction for testing period \n",
    "    - input to model\n",
    "      - lags = previous x time steps to predict the next step\n",
    "      - n_estimators: number of trees\n",
    "6. calcualte MSE for predicted and testing data\n",
    "7. save data (predicted NDVI and MSE) to netCDF file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ce59a9-da0e-4e76-982d-d05891ab55c2",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad6b902b-f57b-4922-bd0a-9181356e84bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "from darts.models import RandomForest\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc784e36-69af-471f-8884-a4dd016d3120",
   "metadata": {},
   "source": [
    "## Define base directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32a5bded-44fc-4cd9-9ebb-3f363028d045",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cgoehler/team-extra/ndvi-time-series-prediction\n"
     ]
    }
   ],
   "source": [
    "# Define base_dir for consistent path management\n",
    "notebook_dir = Path(os.getcwd()).resolve()\n",
    "base_dir = notebook_dir.parent\n",
    "print(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a7db51-6ae1-4705-8c36-9ee8252d19c0",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0302d71-1c2a-4cb8-bf33-0f9c9ae64e0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to load data from NetCDF file and defining variables\n",
    "def load_nc_file(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a NetCDF file.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): Path to the NetCDF file.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the NDVI data, times, x coordinates, and y coordinates.\n",
    "    \"\"\"\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    ndvi = ds['NDVI']\n",
    "    times = ds['time']\n",
    "    x = ds['x']\n",
    "    y = ds['y']\n",
    "    return ndvi, times, x, y\n",
    "\n",
    "# turn data into darts TimeSeries\n",
    "def prepare_darts_timeseries(ndvi_data, times):\n",
    "    \"\"\"\n",
    "    Turn NDVI data into a list of Darts TimeSeries objects.\n",
    "\n",
    "    Parameters:\n",
    "    ndvi_data (xarray.DataArray): The NDVI data array.\n",
    "    times (xarray.DataArray): The time data array.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of Darts TimeSeries objects.\n",
    "    \"\"\"\n",
    "    series_list = []\n",
    "    for i in range(ndvi_data.shape[1]):  # iterate over x dimension\n",
    "        for j in range(ndvi_data.shape[2]):  # iterate over y dimension\n",
    "            values = ndvi_data[:, i, j]\n",
    "            # replace nan values by zeros (assuming only pixels with just NaNs exist)\n",
    "            values = np.nan_to_num(values, nan=0.0)\n",
    "            time_index = pd.to_datetime(times, unit='s')\n",
    "            series = TimeSeries.from_times_and_values(time_index, values)\n",
    "            series_list.append(series)\n",
    "    return series_list\n",
    "\n",
    "# preparing data by turning them into darts TimeSeries\n",
    "def prediction_series(train_ndvi_data, train_times, test_times):\n",
    "    \"\"\"\n",
    "    Train a Random Forest model and predict NDVI values for the test period.\n",
    "\n",
    "    Parameters:\n",
    "    train_ndvi_data (xarray.DataArray): The NDVI data for training.\n",
    "    train_times (xarray.DataArray): The time data for training.\n",
    "    test_times (xarray.DataArray): The time data for testing.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of predicted Darts TimeSeries objects.\n",
    "    \"\"\"\n",
    "    # Train Random Forest model\n",
    "    model = RandomForest(\n",
    "            lags=25,\n",
    "            n_estimators=100)\n",
    "    pred_series = []\n",
    "    for i in range(train_ndvi_data.shape[1]):  # iterate over x dimension\n",
    "        print(f'{i}/{train_ndvi_data.shape[1]}', end='\\r')\n",
    "        for j in range(train_ndvi_data.shape[2]):  # iterate over y dimension\n",
    "            values = train_ndvi_data[:, i, j]\n",
    "            # replace NaN values by zeros (assuming they only exist in pixels that are completely NaN)\n",
    "            values = np.nan_to_num(values, nan=0.0)\n",
    "            time_index = pd.to_datetime(train_times, unit='s')\n",
    "            series = TimeSeries.from_times_and_values(time_index, values)\n",
    "            # train model on training series\n",
    "            model.fit(series)\n",
    "            # predict using random forest model\n",
    "            pred = model.predict(n=len(test_times))\n",
    "            pred_series.append(pred)\n",
    "    return pred_series\n",
    "\n",
    "# Save predictions and MSE to a new NetCDF file\n",
    "def save_to_nc_file(output_file, pred_data, mse_data, times, x, y):\n",
    "    \"\"\"\n",
    "    Save predictions and MSE to a new NetCDF file.\n",
    "\n",
    "    Parameters:\n",
    "    output_file (str): Path to the output NetCDF file.\n",
    "    pred_data (list): List of predicted Darts TimeSeries objects.\n",
    "    mse_data (list): List of Mean Squared Error (MSE) values.\n",
    "    times (numpy.array): Array of time values.\n",
    "    x (numpy.array): Array of x coordinates.\n",
    "    y (numpy.array): Array of y coordinates.\n",
    "    \"\"\"\n",
    "    with nc.Dataset(output_file, 'w', format='NETCDF4') as ds:\n",
    "        ds.createDimension('time', len(times))\n",
    "        ds.createDimension('x', len(x))\n",
    "        ds.createDimension('y', len(y))\n",
    "        \n",
    "        time_var = ds.createVariable('time', 'f4', ('time',))\n",
    "        x_var = ds.createVariable('x', 'f4', ('x',))\n",
    "        y_var = ds.createVariable('y', 'f4', ('y',))\n",
    "        pred_var = ds.createVariable('pred_ndvi', 'f4', ('time', 'x', 'y'))\n",
    "        mse_var = ds.createVariable('mse', 'f4', ('x', 'y'))\n",
    "        \n",
    "        time_var[:] = times\n",
    "        x_var[:] = x\n",
    "        y_var[:] = y\n",
    "        \n",
    "        pred_ndvi = np.array([pred.values().flatten() for pred in pred_data]).reshape((len(times), len(x), len(y)))\n",
    "        pred_var[:] = pred_ndvi\n",
    "        \n",
    "        mse_var[:] = np.array(mse_list).reshape((len(x), len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d82a4f9-c914-4cac-8cda-79e42e27ac4f",
   "metadata": {},
   "source": [
    "## Load data and define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60d6188d-e315-432f-8d26-a8cf17a7bd1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load training and testing data\n",
    "train_path = base_dir / \"data\" / \"data_train\" / \"ds_B_Cube_665_train.nc\"\n",
    "test_path = base_dir / \"data\" / \"data_test\" / \"Cube_665_test.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3cd12a-4dad-4a3e-8b74-0b0decca7ea2",
   "metadata": {},
   "source": [
    "## Train model and make prediction for testing period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de66af0d-dc1d-41d9-878a-0f05f34f129b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with prediction\n"
     ]
    }
   ],
   "source": [
    "# make prediction\n",
    "pred_series = prediction_series(train_ndvi, train_times, test_times)\n",
    "print(\"done with prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2c321d-67fc-45c4-9625-c839b7f24bb3",
   "metadata": {},
   "source": [
    "## Calcualte MSE for predicted and testing data and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff4b0227-9cad-40ea-bb2f-33461d1dc83f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# turn testing data into darts TimeSeries\n",
    "test_series = prepare_darts_timeseries(test_ndvi, test_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a5aebd1b-b0fa-4f6f-9f28-01d943abf587",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with mse\n",
      "done saving\n"
     ]
    }
   ],
   "source": [
    "# Calculate MSE for each pixel between prediction and testing data\n",
    "mse_list = []\n",
    "for pred, actual in zip(pred_series, test_series):\n",
    "    mask = np.isfinite(actual.values().flatten())\n",
    "    mse = mean_squared_error(actual.values().flatten()[mask], pred.values().flatten()[mask])\n",
    "    mse_list.append(mse)\n",
    "print(\"done with mse\")\n",
    "\n",
    "# Save the data (prediction and MSE)\n",
    "pred_path = base_dir / \"data\" / \"data_predictions\"\n",
    "save_to_nc_file(pred_path, 'Random_Forest_Cube_665.nc', pred_series, mse_list, test_times, test_x, test_y)\n",
    "print(\"done saving\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scwenv",
   "language": "python",
   "name": "scwenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
